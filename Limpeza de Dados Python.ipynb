{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Projeto de Limpeza e Tratamento de Valores Ausentes Para Análise de Dados em Python <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes Python Usados no Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma lista para identificar valores ausentes\n",
    "lista_labels_valores_ausentes = [\"n/a\", \"na\", \"undefined\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "telco = pd.read_csv(\"dataset.csv\", na_values = lista_labels_valores_ausentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "telco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número total de colunas para mostrar ao imprimir o dataframe\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostra de dados\n",
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dicionário de dados\n",
    "dicionario = pd.read_excel(\"dicionario.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "dicionario.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define um valor grande para a largura máxima da coluna\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostra de dados\n",
    "dicionario.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "telco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas\n",
    "telco.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não faz sentido calcular estatísticas descritivas para Beared Id, IMSI, MSISDN / Number e IMEI. Mas o método describe() calcula as estatísticas de todas as colunas numéricas. Essas estatísticas estão sendo calculadas antes que os dados sejam limpos. Portanto, pode haver mudanças depois que os valores ausentes e outliers são tratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "telco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "dicionario.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem 150.001 linhas e 55 colunas no dataframe. No entanto, temos 56 colunas com seus nomes e descrições no dicionário. Isso significa que há uma coluna descrita, mas não incluída no dataframe. Vamos identificar qual é a coluna faltante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena os dataframes\n",
    "df_compara_colunas = pd.concat([pd.Series(telco.columns.tolist()), dicionario['Fields']], \n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compara_colunas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia as colunas\n",
    "df_compara_colunas.rename(columns = {0: 'Coluna no Dataset', 'Fields': 'Coluna no Dicionario'}, \n",
    "                          inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "df_compara_colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Dur. (Ms)\" é ignorado no dataset como visto no índice 1 em **df_compara_colunas**. É aqui que a ordem das colunas começou a mudar. \n",
    "\n",
    "Mas o mesmo nome de coluna \"Dur. (Ms)\" aparece no dataset no índice 5, enquanto o arquivo de dicionário nos diz que é \"Dur. (S)\" no índice 6. Como as medidas de ambas as colunas diferem conforme mostrado em seus nomes, nós precisamos verificar qual está certo. Para investigar isso, usaremos a coluna \"Dur. (Ms) .1\" que se encontra nos índices 28 e 29 no dataset e no arquivo de dicionário, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco[['Dur. (ms)', 'Dur. (ms).1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que a coluna \"Dur. (Ms)\" é medida em segundos. Portanto, vamos renomeá-la apropriadamente. Vamos também renomear algumas das colunas para que fiquem claras como sua descrição e sigam o estilo de nomenclatura de outras colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia colunas\n",
    "telco.rename(columns = {'Dur. (ms)': 'Dur (s)', \n",
    "                              'Dur. (ms).1': 'Dur (ms)', \n",
    "                              'Start ms': 'Start Offset (ms)', \n",
    "                              'End ms': 'End Offset (ms)'}, \n",
    "                   inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas do dataset\n",
    "telco.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1 - Tratamento de Valores Ausentes\n",
    "\n",
    "- 1- Identificando Valores Ausentes\n",
    "- 2- Drop de Colunas\n",
    "- 3- Imputação com Preenchimento Reverso\n",
    "- 4- Imputação com Preenchimento Progressivo\n",
    "- 5- Imputação de Variáveis Categóricas\n",
    "- 6- Drop de Linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Identificando Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula o percentual de valores ausentes\n",
    "def func_calc_percent_valores_ausentes(df):\n",
    "\n",
    "    # Calcula o total de células no dataset\n",
    "    totalCells = np.product(df.shape)\n",
    "\n",
    "    # Conta o número de valores ausentes por coluna\n",
    "    missingCount = df.isnull().sum()\n",
    "\n",
    "    # Calcula o total de valores ausentes\n",
    "    totalMissing = missingCount.sum()\n",
    "\n",
    "    # Calcula o percentual de valores ausentes\n",
    "    print(\"O dataset tem\", round(((totalMissing/totalCells) * 100), 2), \"%\", \"de valores ausentes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica o percentual de valores ausentes\n",
    "func_calc_percent_valores_ausentes(telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular valores ausentes por coluna\n",
    "def func_calc_percent_valores_ausentes_coluna(df):\n",
    "    \n",
    "    # Total de valores ausentes\n",
    "    mis_val = df.isnull().sum()\n",
    "\n",
    "    # Porcentagem de valores ausentes\n",
    "    mis_val_percent = 100 * mis_val / len(df)\n",
    "\n",
    "    # Tipo de dado das colunas com valores ausentes\n",
    "    mis_val_dtype = df.dtypes\n",
    "\n",
    "    # Cria uma tabela com os resultados\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent, mis_val_dtype], axis=1)\n",
    "\n",
    "    # Renomear as colunas\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Valores Ausentes', 1 : '% de Valores Ausentes', 2: 'Dtype'})\n",
    "\n",
    "    # Classifica a tabela por porcentagem de valores ausentes de forma decrescente e remove colunas sem valores faltantes\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,0] != 0].sort_values('% de Valores Ausentes', ascending = False).round(2)\n",
    "\n",
    "    # Print \n",
    "    print (\"O dataset tem \" + str(df.shape[1]) + \" colunas.\\n\"\n",
    "        \"Encontrado: \" + str(mis_val_table_ren_columns.shape[0]) + \" colunas que têm valores ausentes.\")\n",
    "\n",
    "    if mis_val_table_ren_columns.shape[0] == 0:\n",
    "        return\n",
    "\n",
    "    # Retorna o dataframe com informações ausentes\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria tabela com valores ausentes\n",
    "df_missing = func_calc_percent_valores_ausentes_coluna(telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Drop de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas que serão removidas\n",
    "colunas_para_remover = df_missing[df_missing['% de Valores Ausentes'] >= 30.00].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas que serão removidas\n",
    "colunas_para_remover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo que as variáveis \"TCP\" tenham muitos valores ausentes, em vez de removê-las, iremos aplicar imputação a essas variáveis, uma vez que elas podem ser necessárias para nossa análise posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas que serão removidas\n",
    "colunas_para_remover = [col for col in colunas_para_remover if col not in ['TCP UL Retrans. Vol (Bytes)',\n",
    "                                                                           'TCP DL Retrans. Vol (Bytes)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas que serão removidas\n",
    "colunas_para_remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop das colunas e cria outro dataframe\n",
    "telco_limpo = telco.drop(colunas_para_remover, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "telco_limpo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos verificar o status dos valores ausentes no dataframe modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes(telco_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes_coluna(telco_limpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Imputação com Preenchimento Reverso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação de valores ausentes usando backward fill\n",
    "# method = 'bfill': Bfill ou backward-fill propaga o primeiro valor não nulo observado para trás até que \n",
    "# outro valor não nulo seja encontrado.\n",
    "def func_fix_missing_bfill(df, col):\n",
    "    \n",
    "    count = df[col].isna().sum()\n",
    "    \n",
    "    df[col] = df[col].fillna(method = 'bfill')\n",
    "    \n",
    "    print(f\"{count} valores ausentes na coluna {col} foram substituídos usando o método de preenchimento reverso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação com Preenchimento Reverso na variável 'TCP UL Retrans. Vol (Bytes)'\n",
    "func_fix_missing_bfill(telco_limpo, 'TCP UL Retrans. Vol (Bytes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação com Preenchimento Reverso na variável 'TCP DL Retrans. Vol (Bytes)'\n",
    "func_fix_missing_bfill(telco_limpo, 'TCP DL Retrans. Vol (Bytes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Imputação com Preenchimento Progressivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes_coluna(telco_limpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg RTT DL (ms) e Avg RTT UL (ms) têm as próximas porcentagens mais altas de valores ausentes com cerca de 18,5% cada. Vamos verificar se as variáveis estão enviesadas (não seguem uma distribuição normal) usando o método skew(), que retorna o coeficiente de assimetria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Avg RTT DL (ms)'].skew(skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Avg RTT UL (ms)'].skew(skipna = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se a assimetria estiver entre -0,5 e 0,5, os dados são bastante simétricos\n",
    "- Se a assimetria estiver entre -1 e - 0,5 ou entre 0,5 e 1, os dados estão moderadamente inclinados\n",
    "- Se a assimetria for menor que -1 ou maior que 1, os dados estão altamente enviesados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto que ambas as colunas Avg RTT DL (ms) e Avg RTT UL (ms) são fortemente enviesadas positivamente é aconselhável não imputá-las com sua média. Portanto, usaremos o preenchimento progressivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação de valores ausentes usando forward fill (preenchimento progressivo)\n",
    "# method = 'ffill': Ffill ou forward-fill propaga o último valor não nulo observado para frente até que \n",
    "# outro valor não nulo seja encontrado\n",
    "def func_fix_missing_ffill(df, col):\n",
    "    \n",
    "    count = df[col].isna().sum()\n",
    "    \n",
    "    df[col] = df[col].fillna(method = 'ffill')\n",
    "    \n",
    "    print(f\"{count} valores ausentes na coluna {col} foram substituídos usando o método de preenchimento progressivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação com Preenchimento Progressivo\n",
    "func_fix_missing_ffill(telco_limpo, 'Avg RTT DL (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação com Preenchimento Progressivo\n",
    "func_fix_missing_ffill(telco_limpo, 'Avg RTT UL (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes(telco_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes_coluna(telco_limpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Imputação de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto que \"Handset Type\" e \"Handset Manufacturer\" são colunas categóricas, é melhor imputá-las com o valor \"unknown\" para que não enviesemos os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenche valor NA\n",
    "def func_fix_missing_value(df, col, value):\n",
    "    \n",
    "    count = df[col].isna().sum()\n",
    "    \n",
    "    df[col] = df[col].fillna(value)\n",
    "    \n",
    "    if type(value) == 'str':\n",
    "        print(f\"{count} valores ausentes na coluna {col} foram substituídos por '{value}'.\")\n",
    "    else:\n",
    "        print(f\"{count} valores ausentes na coluna {col} foram substituídos por {value}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputação de variáveis categóricas\n",
    "func_fix_missing_value(telco_limpo, 'Handset Type', 'unknown')\n",
    "func_fix_missing_value(telco_limpo, 'Handset Manufacturer', 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes(telco_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes_coluna(telco_limpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Drop de Linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que apenas 0.17% do dataset contêm valor ausente e o número total de linhas é de cerca de 150000, descartar essas linhas não terá um impacto negativo perceptível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop de linhas com valores ausentes\n",
    "def func_drop_linhas_com_na(df):\n",
    "    \n",
    "    old = df.shape[0]\n",
    "    \n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    new = df.shape[0]\n",
    "    \n",
    "    count = old - new\n",
    "    \n",
    "    print(f\"{count} linhas contendo valores ausentes foram descartadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop de linhas com valores ausentes\n",
    "func_drop_linhas_com_na(telco_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_calc_percent_valores_ausentes(telco_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "telco_limpo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2 - Conversão de Tipos de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo.select_dtypes(include = 'object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que converte para datetime\n",
    "def func_convert_to_datetime(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte para datetime\n",
    "func_convert_to_datetime(telco_limpo, ['Start', 'End'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair as colunas do tipo object\n",
    "string_columns = telco_limpo.select_dtypes(include = 'object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que converte para string\n",
    "def func_convert_to_string(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte para string\n",
    "func_convert_to_string(telco_limpo, string_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas para conversão\n",
    "int_cols = ['Bearer Id', 'IMSI', 'MSISDN/Number', 'IMEI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que converte para int\n",
    "def func_convert_to_int(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte para int\n",
    "func_convert_to_int(telco_limpo, int_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o drop de linhas duplicadas\n",
    "def func_drop_duplicates(df):\n",
    "    old = df.shape[0]\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    new = df.shape[0]\n",
    "    count = old - new\n",
    "    if (count == 0):\n",
    "        print(\"Nenhuma linha duplicada foi encontrada.\")\n",
    "    else:\n",
    "        print(f\"{count} linhas duplicadas foram encontradas e removidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos checar se há registros duplicados e, se houver, removemos\n",
    "func_drop_duplicates(telco_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de conversão de unidade de tempo\n",
    "def func_converte_unidade(df, columns, factor):\n",
    "    for col in columns:\n",
    "        df[col] = df[col] * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna as linhas das duas colunas\n",
    "temp_df = telco_limpo[['Dur (s)', 'Dur (ms)']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função\n",
    "func_converte_unidade(temp_df, ['Dur (ms)'], 1/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação\n",
    "temp_df['Resultado_Comparacao'] = (temp_df['Dur (s)'] == temp_df['Dur (ms)'].apply(math.floor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As duas colunas são iguais?\n",
    "print(all(temp_df['Resultado_Comparacao']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o drop de colunas\n",
    "def func_drop_columns(df, columns):\n",
    "    df.drop(columns, axis = 1, inplace = True)\n",
    "    count = len(columns)\n",
    "    if count == 1:\n",
    "        print(f\"{count} coluna foi descartada.\")\n",
    "    else:\n",
    "        print(f\"{count} colunas foram descartadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop de coluna\n",
    "func_drop_columns(telco_limpo, ['Dur (s)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3 - Tratamento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define a classe TrataOutlier\n",
    "class TrataOutlier:\n",
    "\n",
    "    # Construtor da classe que inicializa com um DataFrame\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    # Função para contar outliers nas colunas especificadas\n",
    "    def count_outliers(self, Q1, Q3, IQR, columns):\n",
    "        \n",
    "        # Define o limite de corte para considerar um valor como outlier\n",
    "        cut_off = IQR * 1.5\n",
    "        \n",
    "        # Cria um DataFrame temporário com valores booleanos indicando outliers\n",
    "        temp_df = (self.df[columns] < (Q1 - cut_off)) | (self.df[columns] > (Q3 + cut_off))\n",
    "        \n",
    "        # Retorna a contagem de outliers para cada coluna\n",
    "        return [len(temp_df[temp_df[col] == True]) for col in temp_df]\n",
    "\n",
    "    # Função para calcular a assimetria das colunas especificadas\n",
    "    def calc_skew(self, columns=None):\n",
    "        \n",
    "        # Se nenhuma coluna for especificada, utiliza todas as colunas do DataFrame\n",
    "        if columns is None:\n",
    "            columns = self.df.columns\n",
    "        \n",
    "        # Retorna a medida de assimetria para cada coluna\n",
    "        return [self.df[col].skew() for col in columns]\n",
    "\n",
    "    # Função para calcular a porcentagem dos valores em relação ao número de linhas\n",
    "    def percentage(self, values_list):\n",
    "        num_rows = self.df.shape[0]\n",
    "        return [str(round(((value / num_rows) * 100), 2)) + '%' for value in values_list]\n",
    "\n",
    "    # Função para remover outliers nas colunas especificadas\n",
    "    def remove_outliers(self, columns):\n",
    "        for col in columns:\n",
    "            \n",
    "            # Calcula os quantis Q1 e Q3\n",
    "            Q1, Q3 = self.df[col].quantile(0.25), self.df[col].quantile(0.75)\n",
    "            \n",
    "            # Calcula a amplitude interquartil (IQR)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            # Define os limites para considerar um valor como outlier\n",
    "            cut_off = IQR * 1.5\n",
    "            lower, upper = Q1 - cut_off, Q3 + cut_off\n",
    "            \n",
    "            # Remove os valores considerados outliers\n",
    "            self.df = self.df.drop(self.df[self.df[col] > upper].index)\n",
    "            self.df = self.df.drop(self.df[self.df[col] < lower].index)\n",
    "\n",
    "    # Função para substituir outliers pelos valores dos fences nas colunas especificadas\n",
    "    def replace_outliers_with_fences(self, columns):\n",
    "        for col in columns:\n",
    "            \n",
    "            # Calcula os quantis Q1 e Q3\n",
    "            Q1, Q3 = self.df[col].quantile(0.25), self.df[col].quantile(0.75)\n",
    "            \n",
    "            # Calcula a amplitude interquartil (IQR)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            # Define os limites para considerar um valor como outlier\n",
    "            cut_off = IQR * 1.5\n",
    "            lower, upper = Q1 - cut_off, Q3 + cut_off\n",
    "            \n",
    "            # Substitui outliers pelos valores dos fences\n",
    "            self.df[col] = np.where(self.df[col] > upper, upper, self.df[col])\n",
    "            self.df[col] = np.where(self.df[col] < lower, lower, self.df[col])\n",
    "\n",
    "    # Função para obter um resumo estatístico das colunas especificadas\n",
    "    def getOverview(self, columns) -> pd.DataFrame:\n",
    "        \n",
    "        # Calcula diversas estatísticas para as colunas\n",
    "        min_val = self.df[columns].min()\n",
    "        Q1 = self.df[columns].quantile(0.25)\n",
    "        median = self.df[columns].quantile(0.5)\n",
    "        Q3 = self.df[columns].quantile(0.75)\n",
    "        \n",
    "        max_val = self.df[columns].max()\n",
    "        IQR = Q3 - Q1\n",
    "        skew = self.calc_skew(columns)\n",
    "        outliers = self.count_outliers(Q1, Q3, IQR, columns)\n",
    "        cut_off = IQR * 1.5\n",
    "        lower, upper = Q1 - cut_off, Q3 + cut_off\n",
    "        \n",
    "        # Define os nomes das colunas para o novo DataFrame\n",
    "        new_columns = ['Nome de Coluna', \n",
    "                       'Min', \n",
    "                       'Q1', \n",
    "                       'Median', \n",
    "                       'Q3', \n",
    "                       'Max', \n",
    "                       'IQR', \n",
    "                       'Lower fence', \n",
    "                       'Upper fence', \n",
    "                       'Skew', \n",
    "                       'Num_Outliers', \n",
    "                       'Percent_Outliers' ]\n",
    "        \n",
    "        # Cria um novo DataFrame com as estatísticas calculadas\n",
    "        data = zip([column for column in self.df[columns]], min_val, Q1, median, Q3, max_val, IQR, lower, upper, skew, outliers, self.percentage(outliers))\n",
    "        new_df = pd.DataFrame(data=data, columns=new_columns)\n",
    "        \n",
    "        # Define 'Nome de Coluna' como o índice do novo DataFrame\n",
    "        new_df.set_index('Nome de Coluna', inplace=True)\n",
    "        \n",
    "        # Retorna o novo DataFrame ordenado pelo número de outliers\n",
    "        return new_df.sort_values('Num_Outliers', ascending=False).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto trata outlier\n",
    "trata_outlier = TrataOutlier(telco_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas float64\n",
    "lista_colunas = telco_limpo.select_dtypes('float64').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visão geral dos outliers\n",
    "trata_outlier.getOverview(lista_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dos outliers\n",
    "trata_outlier.replace_outliers_with_fences(lista_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visão geral dos outliers\n",
    "trata_outlier.getOverview(lista_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entregando o Resultado da Análise aos Tomadores de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ter a soma dos volumes de dados de upload e download para cada aplicativo como um total pode ser necessário para análises?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Social Media Data Volume (Bytes)'] = dataset_dsa_limpo['Social Media UL (Bytes)'] + dataset_dsa_limpo['Social Media DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Google Data Volume (Bytes)'] = dataset_dsa_limpo['Google UL (Bytes)'] + dataset_dsa_limpo['Google DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Email Data Volume (Bytes)'] = dataset_dsa_limpo['Email UL (Bytes)'] + dataset_dsa_limpo['Email DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Youtube Data Volume (Bytes)'] = dataset_dsa_limpo['Youtube UL (Bytes)'] + dataset_dsa_limpo['Youtube DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Netflix Data Volume (Bytes)'] = dataset_dsa_limpo['Netflix UL (Bytes)'] + dataset_dsa_limpo['Netflix DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Gaming Data Volume (Bytes)'] = dataset_dsa_limpo['Gaming UL (Bytes)'] + dataset_dsa_limpo['Gaming DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Other Data Volume (Bytes)'] = dataset_dsa_limpo['Other UL (Bytes)'] + dataset_dsa_limpo['Other DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo['Total Data Volume (Bytes)'] = dataset_dsa_limpo['Total UL (Bytes)'] + dataset_dsa_limpo['Total DL (Bytes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_limpo.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
